{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Exercise 11 - Recurrent Neural Networks\n",
    "========\n",
    "\n",
    "A recurrent neural network (RNN) is a class of neural network that excels when your data can be treated as a sequence - such as text, music, speech recognition, connected handwriting, or data over a time period. \n",
    "\n",
    "RNN's can analyse or predict a word based on the previous words in a sentence - they allow a connection between previous information and current information.\n",
    "\n",
    "This exercise looks at implementing a LSTM RNN to generate new characters after learning from a large sample of text. LSTMs are a special type of RNN which dramatically improves the model’s ability to connect previous data to current data where there is a long gap.\n",
    "\n",
    "We will train an RNN model using a novel written by H. G. Wells - The Time Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1\n",
    "------\n",
    "\n",
    "Let's start by loading our libraries and text file. This might take a few minutes.\n",
    "\n",
    "#### Run the cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run this!\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM\n",
    "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import random, sys, io, string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the `<addFileName>` with `The Time Machine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated.\n",
      "text length: 174201 characters\n",
      "unique characters: 39\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE THE <addFileName> BELOW WITH The Time Machine\n",
    "###\n",
    "text = io.open('Data/The Time Machine.txt', encoding = 'UTF-8').read()\n",
    "###\n",
    "\n",
    "# Let's have a look at some of the text\n",
    "print(text[0:198])\n",
    "\n",
    "# This cuts out punctuation and make all the characters lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:  \n",
    "```The Time Traveller (for so it will be convenient to speak of him) was expounding a recondite matter to us. His pale grey eyes shone and twinkled, and his usually pale face was flushed and animated.\n",
    "text length: 174201 characters\n",
    "unique characters: 39```\n",
    "\n",
    "Step 2\n",
    "-----\n",
    "\n",
    "Next we'll divide the text into sequences of 40 characters.\n",
    "\n",
    "Then for each sequence we'll make a training set - the following character will be the correct output for the test set.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<sequenceLength>` with `40`\n",
    "#### 2. `<step>` with `4`\n",
    "#### and then __run the code__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training sequences: 43541\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <sequenceLength> WITH 40 AND <step> WITH 4\n",
    "###\n",
    "sequence_length = 40\n",
    "step = 4\n",
    "###\n",
    "\n",
    "sequences = []\n",
    "target_chars = []\n",
    "for i in range(0, len(text) - sequence_length, step):\n",
    "    sequences.append([text[i: i + sequence_length]])\n",
    "    target_chars.append(text[i + sequence_length])\n",
    "print('number of training sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "`number of training sequences: 43541`\n",
    "\n",
    "#### Replace `<addSequences>` with `sequences` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot vectorise\n",
    "\n",
    "X = np.zeros((len(sequences), sequence_length, len(charset)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(charset)), dtype=np.bool)\n",
    "\n",
    "###\n",
    "# REPLACE THE <addSequences> BELOW WITH sequences\n",
    "###\n",
    "for n, sequence in enumerate(sequences):\n",
    "###\n",
    "    for m, character in enumerate(list(sequence[0])):\n",
    "        X[n, m, index_from_char[character]] = 1\n",
    "    y[n, index_from_char[target_chars[n]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3\n",
    "------\n",
    "\n",
    "Let's build our model, using a single LSTM layer of 128 units. We'll keep the model simple for now, so that training does not take too long.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<addLSTM>` with `LSTM`\n",
    "#### 2. `<addLayerSize>` with `128`\n",
    "#### 3. `<addSoftmaxFunction>` with `'softmax`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "###\n",
    "# REPLACE THE <addLSTM> BELOW WITH LSTM (use uppercase) AND <addLayerSize> WITH 128\n",
    "###\n",
    "model.add(LSTM(128, input_shape = (X.shape[1], X.shape[2])))\n",
    "###\n",
    "\n",
    "###\n",
    "# REPLACE THE <addSoftmaxFunction> with 'softmax' (INCLUDING THE QUOTES)\n",
    "###\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "###\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates text at the end of an epoch (one training cycle). This allows us to see how the model is performing as it trains. If you're making a large neural network with a long training time it's useful to check in on the model as see if the text generating is legible as it trains, as overtraining may occur and the output of the model turn to nonsense.\n",
    "\n",
    "The code below will also save a model if it is the best performing model, so we can use it later.\n",
    "\n",
    "#### Run the code below, but don't change it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this, but do not edit.\n",
    "# It helps generate the text and save the model epochs.\n",
    "\n",
    "# Generate new text\n",
    "def on_epoch_end(epoch, _):\n",
    "    diversity = 0.5\n",
    "    print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "\n",
    "    start = random.randint(0, len(text) - sequence_length - 1)\n",
    "    seed = text[start: start + sequence_length]\n",
    "    print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "    output = seed[:40].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    print(output, end = '')\n",
    "\n",
    "    for i in range(500):\n",
    "        x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "        for t, char in enumerate(output):\n",
    "            x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "        predictions = model.predict(x_pred, verbose=0)[0]\n",
    "        exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "        next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "        next_char = char_from_index[next_index]\n",
    "\n",
    "        output = output[1:] + next_char\n",
    "\n",
    "        print(next_char, end = '')\n",
    "    print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# Save the model\n",
    "checkpoint = ModelCheckpoint('Models/model-epoch-{epoch:02d}.hdf5', \n",
    "                             monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will start the model to train. This may take a long time. Feel free to stop the training with the `square stop button` to the right of the `Run button` in the toolbar.\n",
    "\n",
    "Later in the exercise, we will load a pretrained model.\n",
    "\n",
    "### In the cell below replace:\n",
    "#### 1. `<addPrintCallback>` with `print_callback`\n",
    "#### 2. `<addCheckpoint>` with `checkpoint`\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43541 samples\n",
      "Epoch 1/3\n",
      "43520/43541 [============================>.] - ETA: 0s - loss: 2.7339\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \" seemed strangely disconcerted ‘goodbye \"\n",
      " seemed strangely disconcerted ‘goodbye sererge ay shel an  onld anoef anl min as an on wins i an itan thrr ai dtlur semr anre whe ha iseld ar the sin in aa ial ter ont ai an ati ce foui the s aang war se he he fharcfoo an to arn fas iu in to we acacha the laae in core in theg ohe sotwe te ian tha be yole soniu nue he aa sint po be ane one in siee ial lce sfhe the ie arir  ale theks pns ine ou sharelli f pee in ii ohd anle mos on te sinen thesthoi at mle mo macre ine waas lo i ase mo se ee sd and oy in the in the be the lae eame ule s\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.73391, saving model to Models/model-epoch-01.hdf5\n",
      "43541/43541 [==============================] - 59s 1ms/sample - loss: 2.7339\n",
      "Epoch 2/3\n",
      "43520/43541 [============================>.] - ETA: 0s - loss: 2.3409\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"ones lay beside it in the thick dust and\"\n",
      "ones lay beside it in the thick dust and and of and whe the the ind find had thi the the if the the the the the soon ande ind soud bos wean son andas inle ind the ind haching in the and inge poat the thar ion the ous the the thed the the beret the the the sfre the the the ther fres ang if eor of the the aad at af sore the toul me the the pank to the ind afelin the the the the the we cof she hare ond ing she the the sime loon ind and the the bof thing the the tind ruand on as ace ind ind and the burat ande and the red thering of ore th\n",
      "\n",
      "Epoch 00002: loss improved from 2.73391 to 2.34090, saving model to Models/model-epoch-02.hdf5\n",
      "43541/43541 [==============================] - 52s 1ms/sample - loss: 2.3409\n",
      "Epoch 3/3\n",
      "43520/43541 [============================>.] - ETA: 0s - loss: 2.2028\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \"s it proved my chances of finding the ti\"\n",
      "s it proved my chances of finding the time it ing the that it the hevear ind and on and int of at was and the “fere the and and the he hathe ing and wo the was and too keache the thathe toute the sore the sound the me ther and the the wire weathe ind and the the ther inde merey and and und the mate sout and i the the mithe s alithe coule the and it ling and and in the the fit an the sathe bas the thollt e aling the i the sin in the wath sant uat in wore thee the the that toe waic in the mert arde wats the ine thick the int of the sime\n",
      "\n",
      "Epoch 00003: loss improved from 2.34090 to 2.20268, saving model to Models/model-epoch-03.hdf5\n",
      "43541/43541 [==============================] - 56s 1ms/sample - loss: 2.2027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b1cdf50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <addPrintCallback> WITH print_callback AND <addCheckpoint> WITH checkpoint\n",
    "###\n",
    "model.fit(X, y, batch_size = 128, epochs = 3, callbacks = [print_callback, checkpoint])\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output won't appear to be very good. But then, this dataset is small, and we have trained it only for a short time using a rather small RNN. How might it look if we upscaled things?\n",
    "\n",
    "Step 5\n",
    "------\n",
    "\n",
    "We could improve our model by:\n",
    "* Having a larger training set.\n",
    "* Increasing the number of LSTM units.\n",
    "* Training it for longer\n",
    "* Experimenting with difference activation functions, optimization functions etc\n",
    "\n",
    "Training this would still take far too long on most computers to see good results - so we've trained a model already for you.\n",
    "\n",
    "This model uses a different dataset - a few of the King Arthur tales pasted together. The model used:\n",
    "* sequences of 50 characters\n",
    "* Two LSTM layers (512 units each)\n",
    "* A dropout of 0.5 after each LSTM layer\n",
    "* Only 30 epochs (we'd recomend 100-200)\n",
    "\n",
    "Let's try importing this model that has already been trained.\n",
    "\n",
    "#### Replace `<addLoadModel>` with `load_model` and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model... model loaded\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "print(\"loading model... \", end = '')\n",
    "\n",
    "###\n",
    "# REPLACE <addLoadModel> BELOW WITH load_model\n",
    "###\n",
    "model = load_model('Models/arthur-model-epoch-30.hdf5')\n",
    "###\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')\n",
    "###\n",
    "\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6\n",
    "-------\n",
    "\n",
    "Now let's use this model to generate some new text!\n",
    "\n",
    "#### Replace `<addFilePath>` with `'Data/Arthur tales.txt'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 3645951 characters\n",
      "unique characters: 43\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# REPLACE <addFilePath> BELOW WITH 'Data/Arthur tales.txt' (INCLUDING THE QUOTATION MARKS)\n",
    "###\n",
    "text = io.open('Data/Arthur tales.txt', encoding='UTF-8').read()\n",
    "###\n",
    "\n",
    "# Cut out punctuation and make lower case\n",
    "text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Character index dictionary\n",
    "charset = sorted(list(set(text)))\n",
    "index_from_char = dict((c, i) for i, c in enumerate(charset))\n",
    "char_from_index = dict((i, c) for i, c in enumerate(charset))\n",
    "\n",
    "print('text length: %s characters' %len(text))\n",
    "print('unique characters: %s' %len(charset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the cell below replace:\n",
    "#### 1. `<sequenceLength>` with `50`\n",
    "#### 2. `<writeSentence>` with a sentence of your own, at least 50 characters long.\n",
    "#### 3. `<numCharsToGenerate>` with the number of characters you want to generate (choose a large number, like 1500)\n",
    "#### and then __run the code__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Generating text with diversity 0.50\n",
      "### Generating with seed: \" britain from the three plagues  and fro\"\n",
      " britain from the three plagues  and from thenceforth they all the fountain and the country and the stroke of the wise of the castle that he was with a great spear and then sir palomides smote down his spear in his hand and said to him “the boy which thou"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "\n",
    "diversity = 0.5\n",
    "print('\\n### Generating text with diversity %0.2f' %(diversity))\n",
    "\n",
    "###\n",
    "# REPLACE <sequenceLength> BELOW WITH 50\n",
    "###\n",
    "sequence_length = 50\n",
    "###\n",
    "\n",
    "# Next we'll make a starting point for our text generator\n",
    "\n",
    "###\n",
    "# REPLACE <writeSentence> WITH A SENTENCE OF AT LEAST 50 CHARACTERS\n",
    "###\n",
    "# seed = \"It was a great day. The clouds were painted a deep shade of orange, and the ocean looked as if it was on fire. Even the winds were asleep.\"\n",
    "###\n",
    "\n",
    "# seed = seed.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "###\n",
    "# OR, ALTERNATIVELY, UNCOMMENT THE FOLLOWING TWO LINES AND GRAB A RANDOM STRING FROM THE TEXT FILE\n",
    "###\n",
    "\n",
    "start = random.randint(0, len(text) - sequence_length - 1)\n",
    "seed = text[start: start + sequence_length]\n",
    "\n",
    "###\n",
    "\n",
    "print('### Generating with seed: \"%s\"' %seed[:40])\n",
    "\n",
    "output = seed[:sequence_length].lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "print(output, end = '')\n",
    "\n",
    "###\n",
    "# REPLACE THE <numCharsToGenerate> BELOW WITH THE NUMBER OF CHARACTERS WE WISH TO GENERATE, e.g. 1500\n",
    "###\n",
    "for i in range(500):\n",
    "###\n",
    "    x_pred = np.zeros((1, sequence_length, len(charset)))\n",
    "    for t, char in enumerate(output):\n",
    "        x_pred[0, t, index_from_char[char]] = 1.\n",
    "\n",
    "    predictions = model.predict(x_pred, verbose=0)[0]\n",
    "    exp_preds = np.exp(np.log(np.asarray(predictions).astype('float64')) / diversity)\n",
    "    next_index = np.argmax(np.random.multinomial(1, exp_preds / np.sum(exp_preds), 1))\n",
    "    next_char = char_from_index[next_index]\n",
    "\n",
    "    output = output[1:] + next_char\n",
    "\n",
    "    print(next_char, end = '')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it look? Does it seem intelligible?\n",
    "\n",
    "Conclusion\n",
    "--------\n",
    "\n",
    "We have trained an RNN that learns to predict characters based on a text sequence. We have trained a lightweight model from scratch, as well as imported a pre-trained model and generated new text from that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('JupyterEnv': venv)",
   "language": "python",
   "name": "python37664bitjupyterenvvenv7e2094136c454c608a15b7e71cca4f80"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
